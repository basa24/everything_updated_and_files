# -*- coding: utf-8 -*-
"""loop with correct matching frcnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G0BFq62uJDUmxSGFcaGeCf46woawuv61
"""

# -*- coding: utf-8 -*-
"""FRCNN_inference_evaluation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17epi8Cv1nOh0eLt7CnY7O2I6GKrZ7VP_
"""

!pip install torch torchvision
import pandas as pd
import torch
import torchvision
from torchvision import transforms as T
import time
from PIL import Image
import cv2
import os
import json
import numpy as np
from google.colab.patches import cv2_imshow


coco_names = ["person" , "bicycle" , "car" , "motorcycle" , "airplane" , "bus" , "train" , "truck" , "boat" , "traffic light" , "fire hydrant" , "street sign" , "stop sign" , "parking meter" , "bench" , "bird" , "cat" , "dog" , "horse" , "sheep" , "cow" , "elephant" , "bear" , "zebra" , "giraffe" , "hat" , "backpack" , "umbrella" , "shoe" , "eye glasses" , "handbag" , "tie" , "suitcase" ,
"frisbee" , "skis" , "snowboard" , "sports ball" , "kite" , "baseball bat" ,
"baseball glove" , "skateboard" , "surfboard" , "tennis racket" , "bottle" ,
"plate" , "wine glass" , "cup" , "fork" , "knife" , "spoon" , "bowl" ,
"banana" , "apple" , "sandwich" , "orange" , "broccoli" , "carrot" , "hot dog" ,
"pizza" , "donut" , "cake" , "chair" , "couch" , "potted plant" , "bed" ,
"mirror" , "dining table" , "window" , "desk" , "toilet" , "door" , "tv" ,
"laptop" , "mouse" , "remote" , "keyboard" , "cell phone" , "microwave" ,
"oven" , "toaster" , "sink" , "refrigerator" , "blender" , "book" ,
"clock" , "vase" , "scissors" , "teddy bear" , "hair drier" , "toothbrush" , "hair brush"]

import torchvision.models.detection as detection

# Load the pre-trained Faster R-CNN model
model = detection.fasterrcnn_resnet50_fpn(pretrained=True)
if torch.cuda.is_available():
    model.cuda()  # Move model to GPU
if torch.cuda.is_available():
    print("GPU is available!")
else:
    print("GPU is not available.")

model.eval()

# Replace 'your_file.json' with the path to your actual JSON file
file_path = '/content/drive/MyDrive/files and others for ee/imagesvalidationids.json'

with open(file_path, 'r') as file:
    data = json.load(file)
file_name_to_id = {item['file_name']: item['id'] for item in data}

print(file_name_to_id)

file_path = '/content/drive/MyDrive/files and others for ee/categoriesvalidation.json'
with open(file_path, 'r') as file:
    data = json.load(file)
categoryid_to_name = {item['id']: item['name'] for item in data}

print(categoryid_to_name)

resolutions=[640]
confidence = [0, 0.2, 0.4, 0.6, 0.8]

for r in resolutions:
  resolution=r
  for c in confidence:
    obj=[]
    times=[]
    scrs=[]
    boxes=[]
    image_names = []
    image_id_perdetection=[]
    from os import listdir
    directory="/content/drive/MyDrive/valid"
    for image in os.listdir(directory):
      image_path = "/content/drive/MyDrive/valid/"+image
      #print(image_path) works, every path accessed
      ig = Image.open(image_path)
      new_size = (resolution, resolution)
      ig_resized = ig.resize(new_size)

      # Convert the resized image to tensor
      transform = T.ToTensor()
      img = transform(ig_resized)


      start_time = time.time()

      with torch.no_grad():
        pred = model([img])

      end_time_model = time.time()  # Time after model prediction

      # Apply confidence threshold
      bboxes, labels, scores = pred[0]["boxes"], pred[0]["labels"], pred[0]["scores"]
      keep = scores > c
      bboxes = bboxes[keep]
      labels = labels[keep]
      scores = scores[keep]

      end_time_filtering = time.time()  # Time after filtering

      elapsed_time_model = end_time_model - start_time
      elapsed_time_filtering = end_time_filtering - end_time_model
      elapsed_time_approx = elapsed_time_model + elapsed_time_filtering
      times.append(elapsed_time_approx)

      #print(f"Time taken for model inference: {elapsed_time_model:.3f} seconds")
      #print(f"Time taken for filtering: {elapsed_time_filtering:.3f} seconds")
      #print(f"Approximate inference time for high-confidence objects: {elapsed_time_approx:.3f} seconds")

      num = len(bboxes)  # Update number of detections

      # ... (rest of the code for drawing bounding boxes, etc.)
      #loop for each pred, all preds should be in an array

      image_id = file_name_to_id[image]
      for i in range(num):

        class_name = coco_names[labels.numpy()[i] - 1]

        scores_text = f"{class_name} {scores[i].item():.2f}"  # Corrected here
        int_bbox = bboxes[i].numpy().astype(int)
        boxes.append(int_bbox)
        obj.append(class_name)
        scrs.append(scores[i].item())
        image_id_perdetection.append(image_id)


    dict = {'image id': image_id_perdetection, 'name': obj, 'bounding box': boxes, 'confidence': scrs }

    df = pd.DataFrame(dict)

    pd.set_option('display.max_rows', None)  # This will allow all rows to be displayed
    pd.set_option('display.max_columns', None)  # This will allow all columns to be displayed

    df_sorted = df.sort_values(by='image id', ascending=True)

    # If you want to modify the original DataFrame in-place, you can use:
    # df.sort_values(by='image id', ascending=True, inplace=True)
    df_sorted.reset_index(inplace=True, drop=True)

    # Now add a new column 'bbox_id' which is just a sequence of numbers equal to the row number
    df_sorted['bbox_id'] = df_sorted.index
    df_sorted['bbox_id'] = df_sorted['bbox_id'].astype(int)


    #getting data frame from anotated images
    file_path = '/content/drive/MyDrive/files and others for ee/modified_data_with_boundingboxes_try2.json'
    with open(file_path, 'r') as file:
        data = json.load(file)

    extracted_data = []
    for item in data:
        extracted_data.append({
            'image id': item['image_id'],
            'name': item['category_id'],
            'bounding box': item['bbox']
        })

    df_annot = pd.DataFrame(extracted_data)
    df_annot.reset_index(inplace=True, drop=True)

    # Now add a new column 'bbox_id' which is just a sequence of numbers equal to the row number
    df_annot['gt_id'] = df_annot.index
    df_annot['gt_id'] = df_annot['gt_id'].astype(int)



    def calculate_iou(boxA, boxB):
        # Unpack the bounding box coordinates and calculate their areas
        xA, yA, wA, hA = boxA
        xB, yB, wB, hB = boxB
        areaA = wA * hA
        areaB = wB * hB

        # Convert to corner coordinates
        xAmin, yAmin, xAmax, yAmax = xA, yA, xA + wA, yA + hA
        xBmin, yBmin, xBmax, yBmax = xB, yB, xB + wB, yB + hB

        # Calculate intersection coordinates
        xImin = max(xAmin, xBmin)
        yImin = max(yAmin, yBmin)
        xImax = min(xAmax, xBmax)
        yImax = min(yAmax, yBmax)

        # Calculate intersection area
        interArea = max(xImax - xImin, 0) * max(yImax - yImin, 0)

        # Calculate IoU
        iou = interArea / float(areaA + areaB - interArea)
        return iou
      # Sort df_sorted by 'confidence' to prioritize high confidence predictions
    df_sorted = df_sorted.sort_values(by='confidence', ascending=False)

    # Initialize trackers for matched ground truth and predictions
    matched_gt = set()
    matched_preds = set()

    matches = []

    for _, pred_row in df_sorted.iterrows():
        pred_box = pred_row['bounding box']
        bbox_id = pred_row['bbox_id']
        image_id = pred_row['image id']
        class_name = pred_row['name']
        confidence = pred_row['confidence']

        # Skip if this prediction has already been matched
        if bbox_id in matched_preds:
            continue

        # Filter ground truths for the same image ID and class name that haven't been matched
        gt_filtered = df_annot[(df_annot['image id'] == image_id) &
                              (df_annot['name'] == class_name) &
                              (~df_annot['gt_id'].isin(matched_gt))]

        best_iou = 0
        best_match = None

        for _, gt_row in gt_filtered.iterrows():
            gt_box = gt_row['bounding box']
            gt_id = gt_row['gt_id']
            iou = calculate_iou(pred_box, gt_box)

            if iou > best_iou:
                best_iou = iou
                best_match = (gt_row['gt_id'], gt_box)

        # If a suitable match is found (IoU > 0.5), record the match
        if best_match and best_iou > 0.5:
            matched_gt.add(best_match[0])  # Mark this gt_id as matched
            matched_preds.add(bbox_id)  # Mark this bbox_id as matched

            matches.append({
                'image id': image_id,
                'class name': class_name,
                'pred box': pred_box,
                'gt box': best_match[1],
                'iou': best_iou,
                'confidence': confidence,
                'bbox_id': bbox_id,
                'gt_id': best_match[0]
            })

    # Convert matches to DataFrame for easier analysis
    df_matches_with_confidence = pd.DataFrame(matches)

    # Ensure df_matches_with_confidence now represents a strict one-to-one matching


    print("number of wrong/duplicate detections: "+ str(len(df_sorted)-len(df_matches_with_confidence)))
    print("number of missed detections: "+ str(len(df_annot)-len(df_matches_with_confidence)))

    ious = df_matches_with_confidence['iou']
    average_iou = sum(ious) / len(ious)
    average_time=sum(times) / len(times)
    TP = sum(iou > 0.5 for iou in ious)
    FP = len(df_sorted) - TP
    FN = len(df_annot) - TP


    precision = TP / (TP + FP)
    recall = TP / (TP + FN)
    if (precision+recall)!=0:
     f1_score = 2 * (precision * recall) / (precision + recall)
    else:
      f1_score=0
    print(f"Precision: {precision:.2f} \nRecall: {recall:.2f} \nF1 Score: {f1_score:.2f} \nAverage iou: {average_iou:.2f}\nCorrect Predictions(TP): {TP:.2f} \nMispredictions/duplicate detections(FP): {FP:.2f} \nMissed detections(FN): {FN:.2f} \nAverage time: {average_time:.2f}")

    str_resolution=str(resolution)
    data = {
        "Model": ["Faster RCNN"],
        "Image resolution": [str_resolution+" x "+str_resolution],
        "TP": [TP],
        "FP": [FP],
        "FN": [FN],
        "Precision": [precision],
        "Recall": [recall],
        "F1 Score": [f1_score],
        "Average IoU": [average_iou],
        "Average Time": [average_time]
        }

    # Create the DataFrame
    df_results = pd.DataFrame(data)
    print(df_results)


    # Assuming df_sorted, df_annot, and df_matches are already defined as per your description



    file_path_csv = '/content/drive/MyDrive/files and others for ee/RCNN_evaluation_2nattempt - Sheet1.csv'  # Replace with your actual file path

    # Append the DataFrame to the existing CSV without including the header
    df_results.to_csv(file_path_csv, mode='a', index=False, header=False)

    print(resolution)